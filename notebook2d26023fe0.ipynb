{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1877714,"sourceType":"datasetVersion","datasetId":1118008}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-02T18:25:27.545050Z","iopub.execute_input":"2023-12-02T18:25:27.545411Z","iopub.status.idle":"2023-12-02T18:25:27.573987Z","shell.execute_reply.started":"2023-12-02T18:25:27.545384Z","shell.execute_reply":"2023-12-02T18:25:27.572856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Importing Libraries\n","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\n\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nimport librosa\nimport librosa.display\nimport librosa.effects as le\nimport IPython.display as ipd","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:27.576065Z","iopub.execute_input":"2023-12-02T18:25:27.576390Z","iopub.status.idle":"2023-12-02T18:25:31.925529Z","shell.execute_reply.started":"2023-12-02T18:25:27.576363Z","shell.execute_reply":"2023-12-02T18:25:31.924684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the Dataset\n","metadata":{}},{"cell_type":"code","source":"Tess = \"/kaggle/input/speech-emotion-recognition-en/Tess\"\ntess_directory_list = os.listdir(Tess)\n\n\nlabels = []\npaths = []\n\nfor dir in tess_directory_list:\n    directories = os.listdir(Tess +'/'+ dir)\n    for file in directories:\n        part = file.split('.')[0]\n        part = part.split('_')[-1]\n        if(part==\"ps\"):\n           labels.append(\"surprise\")\n        else:\n           labels.append(part)\n        paths.append(Tess +'/'+ dir + '/' + file)\n       \n# dataframe for emotion of files\nemotion_df = pd.DataFrame(labels, columns=['Emotions'])\npath_df = pd.DataFrame(paths, columns=['Path'])\nTess_df = pd.concat([emotion_df, path_df], axis=1)\nTess_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:31.926648Z","iopub.execute_input":"2023-12-02T18:25:31.927529Z","iopub.status.idle":"2023-12-02T18:25:33.651117Z","shell.execute_reply.started":"2023-12-02T18:25:31.927497Z","shell.execute_reply":"2023-12-02T18:25:33.650343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:33.653510Z","iopub.execute_input":"2023-12-02T18:25:33.654050Z","iopub.status.idle":"2023-12-02T18:25:33.660260Z","shell.execute_reply.started":"2023-12-02T18:25:33.654020Z","shell.execute_reply":"2023-12-02T18:25:33.659248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels[:5]","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:33.661558Z","iopub.execute_input":"2023-12-02T18:25:33.662191Z","iopub.status.idle":"2023-12-02T18:25:33.675464Z","shell.execute_reply.started":"2023-12-02T18:25:33.662161Z","shell.execute_reply":"2023-12-02T18:25:33.674430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame();\ndf['speech'] = paths\ndf['label'] = labels\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:33.677203Z","iopub.execute_input":"2023-12-02T18:25:33.677619Z","iopub.status.idle":"2023-12-02T18:25:33.700083Z","shell.execute_reply.started":"2023-12-02T18:25:33.677590Z","shell.execute_reply":"2023-12-02T18:25:33.699009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['label'].value_counts()\ndf['speech']","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:33.701436Z","iopub.execute_input":"2023-12-02T18:25:33.701795Z","iopub.status.idle":"2023-12-02T18:25:33.711623Z","shell.execute_reply.started":"2023-12-02T18:25:33.701768Z","shell.execute_reply":"2023-12-02T18:25:33.710212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Counting the labels","metadata":{}},{"cell_type":"code","source":"sns.countplot(data=df, x='label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:33.713591Z","iopub.execute_input":"2023-12-02T18:25:33.714553Z","iopub.status.idle":"2023-12-02T18:25:34.024293Z","shell.execute_reply.started":"2023-12-02T18:25:33.714422Z","shell.execute_reply":"2023-12-02T18:25:34.023517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**plotting waveform**","metadata":{}},{"cell_type":"code","source":"def waveplot(data,sr,emotion):\n    plt.figure(figsize=(10,4))\n    plt.title(emotion,size=20)\n    librosa.display.waveshow(data,sr=sr)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:34.025341Z","iopub.execute_input":"2023-12-02T18:25:34.025866Z","iopub.status.idle":"2023-12-02T18:25:34.031992Z","shell.execute_reply.started":"2023-12-02T18:25:34.025838Z","shell.execute_reply":"2023-12-02T18:25:34.030765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emotion = 'fear'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata,sr = librosa.load(path)\nwaveplot(data,sr,emotion)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:34.036410Z","iopub.execute_input":"2023-12-02T18:25:34.036782Z","iopub.status.idle":"2023-12-02T18:25:45.371577Z","shell.execute_reply.started":"2023-12-02T18:25:34.036739Z","shell.execute_reply":"2023-12-02T18:25:45.370553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"plotting spectogram","metadata":{}},{"cell_type":"code","source":"def spectogram(data,sr,emotion):\n   x = librosa.stft(data)\n   xdb = librosa.amplitude_to_db(abs(x))\n   plt.figure(figsize=(10,4))\n   plt.title(emotion,size=20)\n   librosa.display.specshow(xdb,sr=sr,x_axis='time',y_axis='hz')\n   plt.colorbar()\nemotion = 'surprise'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata,sr = librosa.load(path)\nspectogram(data,sr,emotion)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:45.372728Z","iopub.execute_input":"2023-12-02T18:25:45.373205Z","iopub.status.idle":"2023-12-02T18:25:45.953147Z","shell.execute_reply.started":"2023-12-02T18:25:45.373178Z","shell.execute_reply":"2023-12-02T18:25:45.952181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def spectogram(data,sr,emotion):\n   x = librosa.stft(data)\n   xdb = librosa.amplitude_to_db(abs(x))\n   plt.figure(figsize=(10,4))\n   plt.title(emotion,size=20)\n   librosa.display.specshow(xdb,sr=sr,x_axis='time',y_axis='hz')\n   plt.colorbar()\nemotion = 'fear'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata,sr = librosa.load(path)\nspectogram(data,sr,emotion)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:45.954703Z","iopub.execute_input":"2023-12-02T18:25:45.954998Z","iopub.status.idle":"2023-12-02T18:25:46.490668Z","shell.execute_reply.started":"2023-12-02T18:25:45.954972Z","shell.execute_reply":"2023-12-02T18:25:46.489457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def spectogram(data,sr,emotion):\n   x = librosa.stft(data)\n   xdb = librosa.amplitude_to_db(abs(x))\n   plt.figure(figsize=(10,4))\n   plt.title(emotion,size=20)\n   librosa.display.specshow(xdb,sr=sr,x_axis='time',y_axis='hz')\n   plt.colorbar()\nemotion = 'angry'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata,sr = librosa.load(path)\nspectogram(data,sr,emotion)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:46.492072Z","iopub.execute_input":"2023-12-02T18:25:46.492387Z","iopub.status.idle":"2023-12-02T18:25:46.995663Z","shell.execute_reply.started":"2023-12-02T18:25:46.492361Z","shell.execute_reply":"2023-12-02T18:25:46.994835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def spectogram(data,sr,emotion):\n   x = librosa.stft(data)\n   xdb = librosa.amplitude_to_db(abs(x))\n   plt.figure(figsize=(10,4))\n   plt.title(emotion,size=20)\n   librosa.display.specshow(xdb,sr=sr,x_axis='time',y_axis='hz')\n   plt.colorbar()\nemotion = 'happy'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata,sr = librosa.load(path)\nspectogram(data,sr,emotion)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:46.996778Z","iopub.execute_input":"2023-12-02T18:25:46.997380Z","iopub.status.idle":"2023-12-02T18:25:47.522553Z","shell.execute_reply.started":"2023-12-02T18:25:46.997351Z","shell.execute_reply":"2023-12-02T18:25:47.521489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def spectogram(data,sr,emotion):\n   x = librosa.stft(data)\n   xdb = librosa.amplitude_to_db(abs(x))\n   plt.figure(figsize=(10,4))\n   plt.title(emotion,size=20)\n   librosa.display.specshow(xdb,sr=sr,x_axis='time',y_axis='hz')\n   plt.colorbar()\nemotion = 'surprise'\npath = np.array(df['speech'][df['label']==emotion])[0]\ndata,sr = librosa.load(path)\nspectogram(data,sr,emotion)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:47.523887Z","iopub.execute_input":"2023-12-02T18:25:47.524202Z","iopub.status.idle":"2023-12-02T18:25:48.067226Z","shell.execute_reply.started":"2023-12-02T18:25:47.524176Z","shell.execute_reply":"2023-12-02T18:25:48.066148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Extraction","metadata":{}},{"cell_type":"code","source":"def extract_mfcc(fn):\n    y,sr = librosa.load(fn,duration=3,offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40).T,axis=0)\n    return mfcc","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:48.069018Z","iopub.execute_input":"2023-12-02T18:25:48.069787Z","iopub.status.idle":"2023-12-02T18:25:48.077373Z","shell.execute_reply.started":"2023-12-02T18:25:48.069751Z","shell.execute_reply":"2023-12-02T18:25:48.075523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_mfcc(paths[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:48.078789Z","iopub.execute_input":"2023-12-02T18:25:48.079116Z","iopub.status.idle":"2023-12-02T18:25:49.651901Z","shell.execute_reply.started":"2023-12-02T18:25:48.079090Z","shell.execute_reply":"2023-12-02T18:25:49.650633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_mfcc = df['speech'].apply(lambda x: extract_mfcc(x\n                                                  ))","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:25:49.653432Z","iopub.execute_input":"2023-12-02T18:25:49.654593Z","iopub.status.idle":"2023-12-02T18:27:30.067236Z","shell.execute_reply.started":"2023-12-02T18:25:49.654554Z","shell.execute_reply":"2023-12-02T18:27:30.065653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_mfcc","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:30.075083Z","iopub.execute_input":"2023-12-02T18:27:30.079976Z","iopub.status.idle":"2023-12-02T18:27:30.109062Z","shell.execute_reply.started":"2023-12-02T18:27:30.079909Z","shell.execute_reply":"2023-12-02T18:27:30.107872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = [x for x in x_mfcc]\nX = np.array(X)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:30.116551Z","iopub.execute_input":"2023-12-02T18:27:30.120527Z","iopub.status.idle":"2023-12-02T18:27:30.142286Z","shell.execute_reply.started":"2023-12-02T18:27:30.120465Z","shell.execute_reply":"2023-12-02T18:27:30.140816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X = np.expand_dims(X,-1)\n# X.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:30.149253Z","iopub.execute_input":"2023-12-02T18:27:30.153164Z","iopub.status.idle":"2023-12-02T18:27:30.162733Z","shell.execute_reply.started":"2023-12-02T18:27:30.153107Z","shell.execute_reply":"2023-12-02T18:27:30.161312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['label']])","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:30.169708Z","iopub.execute_input":"2023-12-02T18:27:30.173734Z","iopub.status.idle":"2023-12-02T18:27:30.189886Z","shell.execute_reply.started":"2023-12-02T18:27:30.173677Z","shell.execute_reply":"2023-12-02T18:27:30.188756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = y.toarray()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:30.191886Z","iopub.execute_input":"2023-12-02T18:27:30.192648Z","iopub.status.idle":"2023-12-02T18:27:30.200751Z","shell.execute_reply.started":"2023-12-02T18:27:30.192609Z","shell.execute_reply":"2023-12-02T18:27:30.199521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\n\nmodel = Sequential([\n    LSTM(123, return_sequences=False, input_shape=(40, 1)),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Dropout\n\nmodel = Sequential([\n    LSTM(123, return_sequences=False, input_shape=(40, 1)),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax')\n])\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:30.202323Z","iopub.execute_input":"2023-12-02T18:27:30.202854Z","iopub.status.idle":"2023-12-02T18:27:39.036674Z","shell.execute_reply.started":"2023-12-02T18:27:30.202774Z","shell.execute_reply":"2023-12-02T18:27:39.035602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n\nmodel_cnn = Sequential([\n    Conv1D(64, kernel_size=3, activation='relu', input_shape=(40, 1)),\n    MaxPooling1D(pool_size=2),\n    Flatten(),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n    Dense(7, activation='softmax')\n])\n\nmodel_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel_cnn.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:39.038331Z","iopub.execute_input":"2023-12-02T18:27:39.038828Z","iopub.status.idle":"2023-12-02T18:27:39.164229Z","shell.execute_reply.started":"2023-12-02T18:27:39.038786Z","shell.execute_reply":"2023-12-02T18:27:39.162923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model_cnn.fit(X,y,validation_split=0.2,epochs=100,batch_size=512,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:39.166801Z","iopub.execute_input":"2023-12-02T18:27:39.167183Z","iopub.status.idle":"2023-12-02T18:27:54.465552Z","shell.execute_reply.started":"2023-12-02T18:27:39.167156Z","shell.execute_reply":"2023-12-02T18:27:54.464418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = list(range(100))\nloss = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs,loss,label = 'accuracy')\nplt.plot(epochs,val_acc,label = 'val_accuracy')\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:54.467427Z","iopub.execute_input":"2023-12-02T18:27:54.467793Z","iopub.status.idle":"2023-12-02T18:27:54.756374Z","shell.execute_reply.started":"2023-12-02T18:27:54.467762Z","shell.execute_reply":"2023-12-02T18:27:54.755306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_classification\n\n# Generate a synthetic dataset for demonstration\n# X, y = make_classification(n_samples=1000, n_features=40, n_informative=20, n_classes=7, random_state=42)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=100)\n\n# Standardize features (important for KNN)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Create a KNN classifier with, for example, k=3\nknn_classifier = KNeighborsClassifier(n_neighbors=3)\n\n# Train the classifier\nknn_classifier.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = knn_classifier.predict(X_test)\n\n# Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:54.762676Z","iopub.execute_input":"2023-12-02T18:27:54.763214Z","iopub.status.idle":"2023-12-02T18:27:55.622803Z","shell.execute_reply.started":"2023-12-02T18:27:54.763180Z","shell.execute_reply":"2023-12-02T18:27:55.621538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the Iris dataset\n# iris = load_iris()\n# X, y = iris.data, iris.target\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for KNN)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Test different values of k (number of neighbors)\nfor k in range(1, 11):\n    # Create a KNN classifier with the current value of k\n    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n\n    # Train the classifier\n    knn_classifier.fit(X_train, y_train)\n\n    # Make predictions on the test set\n    y_pred = knn_classifier.predict(X_test)\n\n    # Evaluate accuracy\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Accuracy for k={k}: {accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:55.624259Z","iopub.execute_input":"2023-12-02T18:27:55.625341Z","iopub.status.idle":"2023-12-02T18:27:58.406955Z","shell.execute_reply.started":"2023-12-02T18:27:55.625301Z","shell.execute_reply":"2023-12-02T18:27:58.405708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import StandardScaler\n\n# Generate a synthetic dataset for demonstration\n# In a real-world scenario, you would replace this with your own dataset\n# X, y = make_classification(n_samples=1000, n_features=40, n_informative=20, n_classes=7, random_state=42)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for KNN)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Create a KNN classifier\nknn_classifier = KNeighborsClassifier(n_neighbors=3)\n\n# Train the classifier\nknn_classifier.fit(X_train, y_train)\n\n# Generate random MFCCs for a single audio sample\nrandom_mfcc = np.random.rand(40).reshape(1, -1)\n\n# Standardize the random MFCC using the same scaler\nrandom_mfcc_standardized = scaler.transform(random_mfcc)\n\n# Predict the emotion label for the random MFCC\npredicted_emotion = knn_classifier.predict(random_mfcc_standardized)\n\nprint(f\"Predicted Emotion Label: {predicted_emotion[0]}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:58.408384Z","iopub.execute_input":"2023-12-02T18:27:58.409315Z","iopub.status.idle":"2023-12-02T18:27:58.444336Z","shell.execute_reply.started":"2023-12-02T18:27:58.409272Z","shell.execute_reply":"2023-12-02T18:27:58.442632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import StandardScaler\n\n# Generate a synthetic dataset for demonstration\n# In a real-world scenario, you would replace this with your own dataset\n# X, y = make_classification(n_samples=1000, n_features=40, n_informative=20, n_classes=7, random_state=42)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for KNN)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Create a KNN classifier\nknn_classifier = KNeighborsClassifier(n_neighbors=3)\n\n# Train the classifier\nknn_classifier.fit(X_train, y_train)\n\n# Generate random MFCCs for a single audio sample\nrandom_mfcc = np.random.rand(40).reshape(1, -1)\n\n# Standardize the random MFCC using the same scaler\nrandom_mfcc_standardized = scaler.transform(random_mfcc)\n\n# Predict the emotion label for the random MFCC\npredicted_emotion = knn_classifier.predict(random_mfcc_standardized)\n\n# Generate a random actual emotion label for demonstration\nactual_emotion = np.random.randint(7)  # Assuming 7 different emotions\n\nprint(f\"Actual Emotion Label: {actual_emotion}\")\nprint(f\"Predicted Emotion Label: {predicted_emotion[0]}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:58.446614Z","iopub.execute_input":"2023-12-02T18:27:58.447370Z","iopub.status.idle":"2023-12-02T18:27:58.491108Z","shell.execute_reply.started":"2023-12-02T18:27:58.447320Z","shell.execute_reply":"2023-12-02T18:27:58.489688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import StandardScaler\n\n# Generate a synthetic dataset for demonstration\n# In a real-world scenario, you would replace this with your own dataset\n# X, y = make_classification(n_samples=1000, n_features=40, n_informative=20, n_classes=7, random_state=42)\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize features (important for KNN)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Create a KNN classifier\nknn_classifier = KNeighborsClassifier(n_neighbors=3)\n\n# Train the classifier\nknn_classifier.fit(X_train, y_train)\n\n# Generate 50 random MFCCs and predict their emotions\nnum_samples = 50\nrandom_mfccs = np.random.rand(num_samples, 40)\nrandom_mfccs_standardized = scaler.transform(random_mfccs)\npredicted_emotions = knn_classifier.predict(random_mfccs_standardized)\n\n# Generate random actual emotion labels for demonstration\nactual_emotions = np.random.randint(7, size=num_samples)  # Assuming 7 different emotions\n\n# Calculate accuracy percentage\naccuracy_percentage = accuracy_score(actual_emotions, predicted_emotions) * 100\n\n# Print actual and predicted emotions\nprint(\"Actual Emotion Labels:\", actual_emotions)\nprint(\"Predicted Emotion Labels:\", predicted_emotions)\n\n# Print accuracy percentage\nprint(f\"Accuracy Percentage: {accuracy_percentage:.2f}%\")\n\n# Plot a bar graph of actual vs predicted emotions\nfig, ax = plt.subplots()\nbar_width = 0.35\nindex = np.arange(num_samples)\nbar1 = ax.bar(index, actual_emotions, bar_width, label='Actual Emotions')\nbar2 = ax.bar(index + bar_width, predicted_emotions, bar_width, label='Predicted Emotions')\n\nax.set_xlabel('Sample Index')\nax.set_ylabel('Emotion Labels')\nax.set_title('Actual vs Predicted Emotions')\nax.set_xticks(index + bar_width / 2)\nax.set_xticklabels(index)\nax.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:58.493299Z","iopub.execute_input":"2023-12-02T18:27:58.494225Z","iopub.status.idle":"2023-12-02T18:27:59.531922Z","shell.execute_reply.started":"2023-12-02T18:27:58.494169Z","shell.execute_reply":"2023-12-02T18:27:59.530072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import make_classification\nfrom sklearn.preprocessing import StandardScaler\n\n# Generate a synthetic dataset for demonstration\n# In a real-world scenario, you would replace this with your own dataset\n# X, y = make_classification(n_samples=1000, n_features=40, n_informative=20, n_classes=7, random_state=42)\n\n# Standardize features (important for KNN)\nscaler = StandardScaler()\nX_standardized = scaler.fit_transform(X)\n\n# Create a KNN classifier\nknn_classifier = KNeighborsClassifier(n_neighbors=3)\n\n# Train the classifier\nknn_classifier.fit(X_standardized, y)\n\n# Generate 50 random MFCCs and predict their emotions\nnum_samples = 20\nrandom_mfccs = np.random.rand(num_samples, 40)\nrandom_mfccs_standardized = scaler.transform(random_mfccs)\npredicted_emotions = knn_classifier.predict(random_mfccs_standardized)\n\n# Generate random actual emotion labels for demonstration\nactual_emotions = np.random.randint(7, size=num_samples)  # Assuming 7 different emotions\n\n# Calculate accuracy for each sample\naccuracy_per_sample = [accuracy_score([actual], [predicted]) for actual, predicted in zip(actual_emotions, predicted_emotions)]\n\n# Plot a bar graph of accuracy for each sample\nfig, ax = plt.subplots()\nindex = np.arange(num_samples)\nbar_width = 0.35\n\nbars = ax.bar(index, accuracy_per_sample, bar_width, label='Accuracy per Sample')\n\nax.set_xlabel('Sample Index')\nax.set_ylabel('Accuracy')\nax.set_title('Accuracy for Each Sample')\nax.set_xticks(index)\nax.legend()\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:59.533119Z","iopub.status.idle":"2023-12-02T18:27:59.533594Z","shell.execute_reply.started":"2023-12-02T18:27:59.533377Z","shell.execute_reply":"2023-12-02T18:27:59.533397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = knn_classifier.fit(X,y,validation_split=0.2,epochs=0,batch_size=512,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T18:27:59.535202Z","iopub.status.idle":"2023-12-02T18:27:59.535603Z","shell.execute_reply.started":"2023-12-02T18:27:59.535395Z","shell.execute_reply":"2023-12-02T18:27:59.535412Z"},"trusted":true},"execution_count":null,"outputs":[]}]}